# streamlit_walmart_dashboard_ko.py
# Run: streamlit run streamlit_walmart_dashboard_ko.py
#
# âœ… ì›ë³¸ CSVëŠ” ê·¸ëŒ€ë¡œ ë‘ê³ 
#   - (1) ì»¬ëŸ¼ëª…ì´ í•œêµ­ì–´/ì˜ì–´ ì–´ë–¤ ë²„ì „ì´ë“  ìë™ ì¸ì‹
#   - (2) í™”ë©´(UI/ì°¨íŠ¸)ì—ì„œëŠ” ê°’ê¹Œì§€ í•œêµ­ì–´ë¡œ í‘œì‹œ
#   - (3) ë‚´ë¶€ ê³„ì‚°/í•„í„°/í†µê³„ëŠ” í‘œì¤€(ì˜ë¬¸) ì»¬ëŸ¼ìœ¼ë¡œ ì•ˆì •ì ìœ¼ë¡œ ìˆ˜í–‰

import streamlit as st
import pandas as pd
import numpy as np
from scipy import stats
from itertools import combinations
import plotly.express as px

# -----------------------------
# Page setup
# -----------------------------
st.set_page_config(
    page_title="Walmart êµ¬ë§¤ ë°ì´í„° | Insight Cockpit",
    page_icon="ğŸ§­",
    layout="wide",
)

st.markdown(
    """
<style>
.block-container {padding-top: 1.2rem; padding-bottom: 2rem;}
div[data-testid="metric-container"]{
    border: 1px solid rgba(49, 51, 63, 0.15);
    border-radius: 14px;
    padding: 14px 14px 10px 14px;
    background: rgba(255,255,255,0.02);
}
.small-note {opacity: 0.75; font-size: 0.92rem;}
.badge {display:inline-block; padding:2px 8px; border-radius:999px; border:1px solid rgba(49,51,63,0.25); font-size:0.85rem; margin-right:6px;}
</style>
""",
    unsafe_allow_html=True,
)

# -----------------------------
# Canonical orders (internal)
# -----------------------------
AGE_ORDER = ["0-17", "18-25", "26-35", "36-45", "46-50", "51-55", "55+"]
STAY_ORDER = ["0", "1", "2", "3", "4+"]
CITY_ORDER = ["A", "B", "C"]

# -----------------------------
# Column name mapping
# -----------------------------
CANON_TO_KO_COL = {
    "User_ID": "ê³ ê°ID",
    "Product_ID": "ìƒí’ˆID",
    "Gender": "ì„±ë³„",
    "Age": "ì—°ë ¹ëŒ€",
    "Occupation": "ì§ì—…ì½”ë“œ",
    "City_Category": "ë„ì‹œìœ í˜•",
    "Stay_In_Current_City_Years": "í˜„ë„ì‹œê±°ì£¼ê¸°ê°„",
    "Marital_Status": "ê²°í˜¼ì—¬ë¶€",
    "Product_Category": "ì œí’ˆì¹´í…Œê³ ë¦¬",
    "Purchase": "êµ¬ë§¤ê¸ˆì•¡",
}
KO_TO_CANON_COL = {v: k for k, v in CANON_TO_KO_COL.items()}

# -----------------------------
# Value mapping (display only)
# -----------------------------
GENDER_MAP = {"M": "ë‚¨", "F": "ì—¬"}
CITY_MAP = {"A": "ë„ì‹œìœ í˜• A", "B": "ë„ì‹œìœ í˜• B", "C": "ë„ì‹œìœ í˜• C"}
AGE_MAP = {
    "0-17": "0-17ì„¸",
    "18-25": "18-25ì„¸",
    "26-35": "26-35ì„¸",
    "36-45": "36-45ì„¸",
    "46-50": "46-50ì„¸",
    "51-55": "51-55ì„¸",
    "55+": "55ì„¸+",
}
STAY_MAP = {"0": "0ë…„", "1": "1ë…„", "2": "2ë…„", "3": "3ë…„", "4+": "4ë…„+"}
MARITAL_MAP = {0: "ë¯¸í˜¼", 1: "ê¸°í˜¼"}  # âš ï¸ ì¼ë°˜ì ì¸ í•´ì„(ë°ì´í„°ì…‹ ê´€ë¡€). í•„ìš”í•˜ë©´ ì•„ë˜ì—ì„œ ë°”ê¾¸ì„¸ìš”.

AGE_ORDER_KO = [AGE_MAP[a] for a in AGE_ORDER]
STAY_ORDER_KO = [STAY_MAP[s] for s in STAY_ORDER]
CITY_ORDER_KO = [CITY_MAP[c] for c in CITY_ORDER]


def standardize_columns(df: pd.DataFrame) -> pd.DataFrame:
    """í•œêµ­ì–´/ì˜ì–´ ì»¬ëŸ¼ëª…ì„ ëª¨ë‘ ë°›ì•„ ë‚´ë¶€ í‘œì¤€(ì˜ë¬¸) ì»¬ëŸ¼ìœ¼ë¡œ ë§ì¶¤."""
    df = df.copy()
    df.columns = [c.strip() for c in df.columns]
    rename_map = {c: KO_TO_CANON_COL[c] for c in df.columns if c in KO_TO_CANON_COL}
    if rename_map:
        df = df.rename(columns=rename_map)
    return df


def val_to_ko(col: str, v):
    """ë‚´ë¶€ ê°’ -> í™”ë©´ í‘œì‹œìš© í•œêµ­ì–´ ê°’."""
    if col == "Gender":
        return GENDER_MAP.get(v, str(v))
    if col == "City_Category":
        return CITY_MAP.get(v, str(v))
    if col == "Age":
        return AGE_MAP.get(v, str(v))
    if col == "Stay_In_Current_City_Years":
        return STAY_MAP.get(str(v), str(v))
    if col == "Marital_Status":
        try:
            vv = int(v)
        except Exception:
            vv = v
        return MARITAL_MAP.get(vv, str(v))
    if col == "Occupation":
        return f"ì§ì—… {v}"
    if col == "Product_Category":
        return f"ì¹´í…Œê³ ë¦¬ {v}"
    return str(v)


def to_display_df(df: pd.DataFrame) -> pd.DataFrame:
    """í‘œì‹œìš© DF(í•œêµ­ì–´ ì»¬ëŸ¼ëª… + ê°’ í•œêµ­ì–´í™”). ì›ë³¸/ë¶„ì„ìš© DFëŠ” ê±´ë“œë¦¬ì§€ ì•ŠìŒ."""
    d = df.copy()

    if "Gender" in d.columns:
        d["Gender"] = d["Gender"].map(GENDER_MAP).fillna(d["Gender"].astype(str))

    if "City_Category" in d.columns:
        d["City_Category"] = d["City_Category"].astype(str).map(CITY_MAP).fillna(d["City_Category"].astype(str))

    if "Age" in d.columns:
        d["Age"] = d["Age"].astype(str).map(AGE_MAP).fillna(d["Age"].astype(str))

    if "Stay_In_Current_City_Years" in d.columns:
        d["Stay_In_Current_City_Years"] = d["Stay_In_Current_City_Years"].astype(str).map(STAY_MAP).fillna(
            d["Stay_In_Current_City_Years"].astype(str)
        )

    if "Marital_Status" in d.columns:
        d["Marital_Status"] = d["Marital_Status"].map(MARITAL_MAP).fillna(d["Marital_Status"].astype(str))

    if "Occupation" in d.columns:
        d["Occupation"] = d["Occupation"].astype(str).map(lambda x: f"ì§ì—… {x}")

    if "Product_Category" in d.columns:
        d["Product_Category"] = d["Product_Category"].astype(str).map(lambda x: f"ì¹´í…Œê³ ë¦¬ {x}")

    # rename columns
    d = d.rename(columns=CANON_TO_KO_COL)

    # keep nice ordering
    if "ì—°ë ¹ëŒ€" in d.columns:
        d["ì—°ë ¹ëŒ€"] = pd.Categorical(d["ì—°ë ¹ëŒ€"], categories=AGE_ORDER_KO, ordered=True)
    if "í˜„ë„ì‹œê±°ì£¼ê¸°ê°„" in d.columns:
        d["í˜„ë„ì‹œê±°ì£¼ê¸°ê°„"] = pd.Categorical(d["í˜„ë„ì‹œê±°ì£¼ê¸°ê°„"], categories=STAY_ORDER_KO, ordered=True)
    if "ë„ì‹œìœ í˜•" in d.columns:
        d["ë„ì‹œìœ í˜•"] = pd.Categorical(d["ë„ì‹œìœ í˜•"], categories=CITY_ORDER_KO, ordered=True)

    return d


# -----------------------------
# Data load
# -----------------------------
@st.cache_data(show_spinner=False)
def load_data_from_path(path: str) -> pd.DataFrame:
    df = pd.read_csv(path)
    df = standardize_columns(df)

    # Normalize dtypes/orders (internal)
    if "Age" in df.columns:
        df["Age"] = pd.Categorical(df["Age"].astype(str), categories=AGE_ORDER, ordered=True)

    if "Stay_In_Current_City_Years" in df.columns:
        df["Stay_In_Current_City_Years"] = pd.Categorical(
            df["Stay_In_Current_City_Years"].astype(str), categories=STAY_ORDER, ordered=True
        )

    if "City_Category" in df.columns:
        df["City_Category"] = pd.Categorical(df["City_Category"].astype(str), categories=CITY_ORDER, ordered=True)

    # Keep masked numeric categories as int
    for c in ["Occupation", "Product_Category", "Marital_Status"]:
        if c in df.columns:
            df[c] = df[c].astype("int64")

    return df


def apply_filters(df: pd.DataFrame, f: dict) -> pd.DataFrame:
    out = df
    if f["city"]:
        out = out[out["City_Category"].isin(f["city"])]
    if f["gender"]:
        out = out[out["Gender"].isin(f["gender"])]
    if f["age"]:
        out = out[out["Age"].isin(f["age"])]
    if f["stay"]:
        out = out[out["Stay_In_Current_City_Years"].isin(f["stay"])]
    if f["marital"]:
        out = out[out["Marital_Status"].isin(f["marital"])]
    if f["occupation"]:
        out = out[out["Occupation"].isin(f["occupation"])]
    if f["prodcat"]:
        out = out[out["Product_Category"].isin(f["prodcat"])]

    pr_min, pr_max = f["purchase_range"]
    out = out[(out["Purchase"] >= pr_min) & (out["Purchase"] <= pr_max)]
    return out


# -----------------------------
# Stats helpers
# -----------------------------
def epsilon_squared_kw(H: float, k: int, n: int) -> float:
    if n <= k:
        return np.nan
    return float(max(0.0, (H - k + 1.0) / (n - k)))


def kruskal_with_eps2(df: pd.DataFrame, group_col: str, value_col: str = "Purchase"):
    groups = []
    labels = []
    for g, sub in df.groupby(group_col, observed=True):
        vals = sub[value_col].dropna().values
        if len(vals) >= 2:
            groups.append(vals)
            labels.append(g)

    k = len(groups)
    n = int(sum(len(x) for x in groups))
    if k < 2:
        return None

    H, p = stats.kruskal(*groups)
    eps2 = epsilon_squared_kw(H, k, n)
    return {"H": float(H), "p": float(p), "eps2": float(eps2), "k": k, "n": n, "labels": labels}


def effect_badge(value: float, kind: str = "eps2") -> str:
    if np.isnan(value):
        return "N/A"
    if kind == "eps2":
        if value < 0.01:
            return "signal: tiny"
        if value < 0.06:
            return "signal: small"
        if value < 0.14:
            return "signal: medium"
        return "signal: large"
    if value < 0.10:
        return "signal: tiny"
    if value < 0.30:
        return "signal: small"
    if value < 0.50:
        return "signal: medium"
    return "signal: large"


def cramers_v_from_crosstab(ct: pd.DataFrame) -> dict:
    chi2, p, dof, exp = stats.chi2_contingency(ct.values, correction=False)
    n = ct.values.sum()
    r, c = ct.shape
    denom = n * max(1, (min(r - 1, c - 1)))
    v = np.sqrt(chi2 / denom) if denom > 0 else np.nan
    return {"chi2": float(chi2), "p": float(p), "dof": int(dof), "v": float(v), "n": int(n)}


def mannwhitney_pairwise(df: pd.DataFrame, group_col: str, value_col: str = "Purchase"):
    cats = [c for c in df[group_col].dropna().unique()]
    cats = sorted(cats, key=lambda x: str(x))
    pairs = list(combinations(cats, 2))
    m = len(pairs)
    rows = []

    for a, b in pairs:
        xa = df.loc[df[group_col] == a, value_col].dropna().values
        xb = df.loc[df[group_col] == b, value_col].dropna().values
        if len(xa) < 2 or len(xb) < 2:
            continue
        U, p = stats.mannwhitneyu(xa, xb, alternative="two-sided")
        p_bonf = min(p * m, 1.0)
        rows.append(
            {
                "ë¹„êµ": f"{val_to_ko(group_col, a)} vs {val_to_ko(group_col, b)}",
                "U": float(U),
                "p_raw": float(p),
                "p_bonf": float(p_bonf),
            }
        )

    return pd.DataFrame(rows).sort_values("p_bonf", ascending=True)


def ecdf_df(x: np.ndarray) -> pd.DataFrame:
    x = np.asarray(x)
    x = x[~np.isnan(x)]
    x = np.sort(x)
    y = np.arange(1, len(x) + 1) / len(x) if len(x) else np.array([])
    return pd.DataFrame({"x": x, "y": y})


@st.cache_data(show_spinner=False)
def signal_scoreboard(df: pd.DataFrame, sample_n: int = 120_000, seed: int = 42) -> pd.DataFrame:
    rng = np.random.default_rng(seed)
    if len(df) > sample_n:
        idx = rng.choice(len(df), size=sample_n, replace=False)
        d = df.iloc[idx].copy()
    else:
        d = df.copy()

    cols = ["City_Category", "Gender", "Age", "Stay_In_Current_City_Years", "Marital_Status", "Occupation", "Product_Category"]
    rows = []
    for c in cols:
        if c not in d.columns:
            continue
        res = kruskal_with_eps2(d, c, "Purchase")
        if res is None:
            continue
        rows.append(
            {
                "ë³€ìˆ˜": CANON_TO_KO_COL.get(c, c),
                "í‘œë³¸ìˆ˜(n)": res["n"],
                "ê·¸ë£¹ìˆ˜(k)": res["k"],
                "H": res["H"],
                "p-value": res["p"],
                "íš¨ê³¼í¬ê¸°(ÎµÂ²)": res["eps2"],
                "signal": effect_badge(res["eps2"], "eps2"),
            }
        )

    return pd.DataFrame(rows).sort_values("íš¨ê³¼í¬ê¸°(ÎµÂ²)", ascending=False)


def top3_groups(df: pd.DataFrame, group_col: str, value_col: str = "Purchase") -> pd.DataFrame:
    g = (
        df.groupby(group_col, observed=True)[value_col]
        .agg(count="size", mean="mean", median="median")
        .reset_index()
    )
    g["mean"] = g["mean"].round(2)
    g["median"] = g["median"].round(2)
    return g.sort_values(["mean", "count"], ascending=[False, False])


# -----------------------------
# Sidebar: load + filter
# -----------------------------
st.title("ğŸ§­ Walmart êµ¬ë§¤ ë°ì´í„° Insight Cockpit")

with st.sidebar:
    st.header("âš™ï¸ ë°ì´í„° & í•„í„°")

    uploaded = st.file_uploader("CSV ì—…ë¡œë“œ (ì—†ìœ¼ë©´ ê¸°ë³¸ walmart.csv ì‚¬ìš©)", type=["csv"])
    default_path = "walmart.csv"

    if uploaded is not None:
        df_raw = pd.read_csv(uploaded)
        df_raw = standardize_columns(df_raw)
        # mirror preprocessing
        if "Age" in df_raw.columns:
            df_raw["Age"] = pd.Categorical(df_raw["Age"].astype(str), categories=AGE_ORDER, ordered=True)
        if "Stay_In_Current_City_Years" in df_raw.columns:
            df_raw["Stay_In_Current_City_Years"] = pd.Categorical(
                df_raw["Stay_In_Current_City_Years"].astype(str), categories=STAY_ORDER, ordered=True
            )
        if "City_Category" in df_raw.columns:
            df_raw["City_Category"] = pd.Categorical(df_raw["City_Category"].astype(str), categories=CITY_ORDER, ordered=True)

        for c in ["Occupation", "Product_Category", "Marital_Status"]:
            if c in df_raw.columns:
                df_raw[c] = df_raw[c].astype("int64")
    else:
        df_raw = load_data_from_path(default_path)

    st.markdown('<div class="small-note">í•„í„°ëŠ” "ì§€ê¸ˆ ë³´ê³  ìˆëŠ” ì„¸ê·¸ë¨¼íŠ¸" ê¸°ì¤€ìœ¼ë¡œ í†µê³„/ì°¨íŠ¸ë¥¼ ë‹¤ì‹œ ê³„ì‚°í•´ìš”.</div>', unsafe_allow_html=True)

    # Filters: options are canonical values, but shown as Korean via format_func
    city = st.multiselect(
        "ë„ì‹œìœ í˜•",
        options=list(df_raw["City_Category"].cat.categories),
        default=[],
        format_func=lambda x: val_to_ko("City_Category", x),
    )
    gender = st.multiselect(
        "ì„±ë³„",
        options=sorted(df_raw["Gender"].unique()),
        default=[],
        format_func=lambda x: val_to_ko("Gender", x),
    )
    age = st.multiselect(
        "ì—°ë ¹ëŒ€",
        options=list(df_raw["Age"].cat.categories),
        default=[],
        format_func=lambda x: val_to_ko("Age", x),
    )
    stay = st.multiselect(
        "í˜„ë„ì‹œê±°ì£¼ê¸°ê°„",
        options=list(df_raw["Stay_In_Current_City_Years"].cat.categories),
        default=[],
        format_func=lambda x: val_to_ko("Stay_In_Current_City_Years", x),
    )

    marital = st.multiselect(
        "ê²°í˜¼ì—¬ë¶€",
        options=sorted(df_raw["Marital_Status"].unique()),
        default=[],
        format_func=lambda x: val_to_ko("Marital_Status", x),
    )
    occupation = st.multiselect(
        "ì§ì—…ì½”ë“œ",
        options=sorted(df_raw["Occupation"].unique()),
        default=[],
        format_func=lambda x: val_to_ko("Occupation", x),
    )
    prodcat = st.multiselect(
        "ì œí’ˆì¹´í…Œê³ ë¦¬",
        options=sorted(df_raw["Product_Category"].unique()),
        default=[],
        format_func=lambda x: val_to_ko("Product_Category", x),
    )

    pr_min = int(df_raw["Purchase"].min())
    pr_max = int(df_raw["Purchase"].max())
    purchase_range = st.slider("êµ¬ë§¤ê¸ˆì•¡ ë²”ìœ„", min_value=pr_min, max_value=pr_max, value=(pr_min, pr_max))

    filters = dict(
        city=city,
        gender=gender,
        age=age,
        stay=stay,
        marital=marital,
        occupation=occupation,
        prodcat=prodcat,
        purchase_range=purchase_range,
    )

df = apply_filters(df_raw, filters)
df_disp = to_display_df(df)  # charts/UIìš©

# -----------------------------
# Top ribbon: quick status
# -----------------------------
kpi1, kpi2, kpi3, kpi4, kpi5 = st.columns(5)
kpi1.metric("ê±°ë˜ ìˆ˜", f"{len(df):,}")
kpi2.metric("ê³ ê° ìˆ˜", f"{df['User_ID'].nunique():,}")
kpi3.metric("ìƒí’ˆ ìˆ˜", f"{df['Product_ID'].nunique():,}")
kpi4.metric("ì´ êµ¬ë§¤ê¸ˆì•¡", f"{int(df['Purchase'].sum()):,}")
kpi5.metric("í‰ê·  êµ¬ë§¤ê¸ˆì•¡", f"{df['Purchase'].mean():,.1f}")

st.markdown(
    f"""
<span class="badge">í˜„ì¬ ë·°</span>
<span class="small-note">í•„í„° ì ìš© í›„ í‘œë³¸: <b>{len(df):,}</b> rows</span>
""",
    unsafe_allow_html=True,
)

tabs = st.tabs(["ğŸ›ï¸ í•œëˆˆì— ë³´ê¸°", "ğŸ§ª ê°€ì„¤ íƒí—˜", "ğŸ§© ì¡°í•© íˆíŠ¸ë§µ", "ğŸ” ì„¸ê·¸ë¨¼íŠ¸ TOP3"])

# -----------------------------
# Tab 1: Overview
# -----------------------------
with tabs[0]:
    left, right = st.columns([1.25, 1])

    with left:
        st.subheader("êµ¬ë§¤ê¸ˆì•¡ ë¶„í¬ (ë¹ ë¥¸ ê° ì¡ê¸°)")
        logx = st.toggle("ë¡œê·¸ ìŠ¤ì¼€ì¼(êµ¬ë§¤ê¸ˆì•¡)", value=False)
        fig = px.histogram(df_disp, x="êµ¬ë§¤ê¸ˆì•¡", nbins=70, marginal="box")
        if logx:
            fig.update_xaxes(type="log")
        st.plotly_chart(fig, use_container_width=True)

        with st.expander("í•„í„°ëœ ë°ì´í„° ë‹¤ìš´ë¡œë“œ"):
            c1, c2 = st.columns(2)
            with c1:
                st.download_button(
                    "CSV ë‹¤ìš´ë¡œë“œ(ì›ë³¸ ì»¬ëŸ¼/ê°’)",
                    data=df.to_csv(index=False).encode("utf-8-sig"),
                    file_name="walmart_filtered_raw.csv",
                    mime="text/csv",
                )
            with c2:
                st.download_button(
                    "CSV ë‹¤ìš´ë¡œë“œ(í•œêµ­ì–´ ì»¬ëŸ¼/ê°’)",
                    data=df_disp.to_csv(index=False).encode("utf-8-sig"),
                    file_name="walmart_filtered_ko.csv",
                    mime="text/csv",
                )

    with right:
        st.subheader("Signal Scoreboard ğŸ")
        st.caption("í‘œë³¸ì´ í¬ë©´ p-valueëŠ” ê±°ì˜ í•­ìƒ ì‘ì•„ì ¸ìš”. ê·¸ë˜ì„œ 'íš¨ê³¼í¬ê¸°(ÎµÂ²)'ë¡œ ë³€ìˆ˜ë³„ ì˜í–¥ë ¥ì„ í•œ ë²ˆì— ë´…ë‹ˆë‹¤.")

        sample_n = st.slider("Scoreboard í‘œë³¸ í¬ê¸°", 30_000, 200_000, 120_000, step=10_000)
        board = signal_scoreboard(df, sample_n=sample_n)

        if len(board):
            st.dataframe(board, use_container_width=True, hide_index=True)

            fig2 = px.bar(
                board.sort_values("íš¨ê³¼í¬ê¸°(ÎµÂ²)", ascending=True),
                x="íš¨ê³¼í¬ê¸°(ÎµÂ²)",
                y="ë³€ìˆ˜",
                orientation="h",
                hover_data=["í‘œë³¸ìˆ˜(n)", "ê·¸ë£¹ìˆ˜(k)", "p-value", "signal"],
            )
            st.plotly_chart(fig2, use_container_width=True)
        else:
            st.info("í•„í„° ë•Œë¬¸ì— ê·¸ë£¹ì´ 1ê°œë§Œ ë‚¨ì•˜ê±°ë‚˜ í‘œë³¸ì´ ë„ˆë¬´ ì‘ì•„ìš”. í•„í„°ë¥¼ ì¡°ê¸ˆ í’€ì–´ë³´ì„¸ìš”.")

    st.divider()
    st.subheader("í•œ ì¤„ ì¸ì‚¬ì´íŠ¸ ìƒì„±ê¸° âœï¸")
    c1, c2 = st.columns([1, 1])
    with c1:
        focus = st.selectbox(
            "ì–´ëŠ ë³€ìˆ˜ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í• ê¹Œ?",
            ["City_Category", "Stay_In_Current_City_Years", "Product_Category", "Gender", "Age", "Occupation", "Marital_Status"],
            format_func=lambda x: CANON_TO_KO_COL.get(x, x),
        )
    with c2:
        mode = st.selectbox("ê¸°ì¤€", ["mean(í‰ê· )", "median(ì¤‘ì•™ê°’)"])

    g = top3_groups(df, focus)
    if len(g):
        g2 = g.copy()
        g2[focus] = g2[focus].apply(lambda v: val_to_ko(focus, v))
        top = g2.iloc[0]
        basis = "mean" if "mean" in mode else "median"
        val = float(top[basis])
        st.success(
            f"í˜„ì¬ í•„í„° ê¸°ì¤€ìœ¼ë¡œ **{CANON_TO_KO_COL.get(focus, focus)}={top[focus]}** ê·¸ë£¹ì´ {mode} ê¸°ì¤€ìœ¼ë¡œ ê°€ì¥ ë†’ì•„ìš” "
            f"(count={int(top['count']):,}, {mode.split('(')[0]}={val:,.1f})."
        )
        st.caption("ì´ ë¬¸ì¥ì„ ê·¸ëŒ€ë¡œ ë°œí‘œ/ë³´ê³ ì„œì— ë°•ì•„ë„ ìì—°ìŠ¤ëŸ½ê²Œ ëŒì•„ê°€ê²Œ ë§Œë“  ë¬¸ì¥ í…œí”Œë¦¿ì´ì—ìš” ğŸ™‚")

# -----------------------------
# Tab 2: Hypotheses explorer
# -----------------------------
with tabs[1]:
    st.subheader("ê°€ì„¤ íƒí—˜ ëª¨ë“œ")
    st.caption("3ê°€ì§€ ê°€ì„¤ì„ ìŠ¤ìœ„ì¹˜ë¡œ ì™”ë‹¤ ê°”ë‹¤ í•˜ë©´ì„œ, ì°¨íŠ¸+ê²€ì •+íš¨ê³¼í¬ê¸°ë¥¼ í•œ í™”ë©´ì— ë¬¶ì—ˆìŠµë‹ˆë‹¤.")

    h = st.radio(
        "ê°€ì„¤ ì„ íƒ",
        ["ê°€ì„¤ 1: ë„ì‹œìœ í˜•ë³„ êµ¬ë§¤ê¸ˆì•¡ ì°¨ì´", "ê°€ì„¤ 2: ê±°ì£¼ê¸°ê°„ë³„ êµ¬ë§¤ê¸ˆì•¡ ì°¨ì´", "ê°€ì„¤ 3: ì œí’ˆì¹´í…Œê³ ë¦¬ì™€ ê³ ê°íŠ¹ì„±(ì„±ë³„/ì—°ë ¹) ì—°ê´€"],
        horizontal=True,
    )

    if h.startswith("ê°€ì„¤ 1"):
        st.markdown("**ì§ˆë¬¸:** ë„ì‹œìœ í˜•(A/B/C)ì— ë”°ë¼ êµ¬ë§¤ê¸ˆì•¡ ë¶„í¬ê°€ ë‹¬ë¼ì§ˆê¹Œ?")
        a, b = st.columns([1.1, 0.9])

        with a:
            fig = px.box(df_disp, x="ë„ì‹œìœ í˜•", y="êµ¬ë§¤ê¸ˆì•¡", points=False)
            st.plotly_chart(fig, use_container_width=True)

            # ECDF: compute from canonical but label in KO
            ecdfs = []
            for c in df["City_Category"].dropna().unique():
                ecdf = ecdf_df(df.loc[df["City_Category"] == c, "Purchase"].values)
                ecdf["ë„ì‹œìœ í˜•"] = val_to_ko("City_Category", c)
                ecdfs.append(ecdf)
            if ecdfs:
                fig_ecdf = px.line(pd.concat(ecdfs, ignore_index=True), x="x", y="y", color="ë„ì‹œìœ í˜•")
                fig_ecdf.update_layout(xaxis_title="êµ¬ë§¤ê¸ˆì•¡", yaxis_title="ëˆ„ì ë¹„ìœ¨(ECDF)")
                st.plotly_chart(fig_ecdf, use_container_width=True)

        with b:
            res = kruskal_with_eps2(df, "City_Category")
            if res is None:
                st.info("ê·¸ë£¹ì´ 2ê°œ ì´ìƒ í•„ìš”í•´ìš”. í•„í„°ë¥¼ ì¡°ì •í•´ë³´ì„¸ìš”.")
            else:
                st.markdown(
                    f"""
- Kruskal-Wallis H = **{res['H']:.3f}**
- p-value = **{res['p']:.3e}**
- íš¨ê³¼í¬ê¸° ÎµÂ² = **{res['eps2']:.6f}**  â†’ **{effect_badge(res['eps2'], 'eps2')}**
"""
                )
                st.caption("p-valueê°€ ì‘ì•„ë„ ÎµÂ²ê°€ ì‘ìœ¼ë©´ 'ì‹¤ë¬´ì  ì°¨ì´ëŠ” ì‘ë‹¤'ë¡œ í•´ì„í•˜ëŠ” ê²Œ ìì—°ìŠ¤ëŸ½ìŠµë‹ˆë‹¤.")

                if st.button("ë„ì‹œìœ í˜• ì‚¬í›„ê²€ì • (Mann-Whitney + Bonferroni) ì‹¤í–‰"):
                    pw = mannwhitney_pairwise(df, "City_Category")
                    st.dataframe(pw, use_container_width=True, hide_index=True)

    elif h.startswith("ê°€ì„¤ 2"):
        st.markdown("**ì§ˆë¬¸:** í˜„ ë„ì‹œ ê±°ì£¼ê¸°ê°„ì— ë”°ë¼ êµ¬ë§¤ê¸ˆì•¡ íŠ¹ì„±ì´ ë‹¬ë¼ì§ˆê¹Œ?")
        a, b = st.columns([1.1, 0.9])

        with a:
            fig = px.box(df_disp, x="í˜„ë„ì‹œê±°ì£¼ê¸°ê°„", y="êµ¬ë§¤ê¸ˆì•¡", points=False)
            st.plotly_chart(fig, use_container_width=True)

        with b:
            res = kruskal_with_eps2(df, "Stay_In_Current_City_Years")
            if res is None:
                st.info("ê·¸ë£¹ì´ 2ê°œ ì´ìƒ í•„ìš”í•´ìš”. í•„í„°ë¥¼ ì¡°ì •í•´ë³´ì„¸ìš”.")
            else:
                st.markdown(
                    f"""
- Kruskal-Wallis H = **{res['H']:.3f}**
- p-value = **{res['p']:.3e}**
- íš¨ê³¼í¬ê¸° ÎµÂ² = **{res['eps2']:.6f}**  â†’ **{effect_badge(res['eps2'], 'eps2')}**
"""
                )

            # Spearman trend (ordinal mapping)
            stay_map = {k: i for i, k in enumerate(STAY_ORDER)}
            x = df["Stay_In_Current_City_Years"].astype(str).map(stay_map)
            rho, p_rho = stats.spearmanr(x, df["Purchase"].values, nan_policy="omit")
            st.markdown(f"- ë‹¨ì¡° ê²½í–¥(Spearman Ï) = **{rho:.4f}** (p={p_rho:.3e})")

            # Variance difference (Levene median)
            groups = [sub["Purchase"].values for _, sub in df.groupby("Stay_In_Current_City_Years", observed=True)]
            if len(groups) >= 2:
                lev_stat, lev_p = stats.levene(*groups, center="median")
                st.markdown(f"- ë¶„ì‚° ì°¨ì´(Levene, median) = **{lev_stat:.3f}** (p={lev_p:.3e})")

    else:
        st.markdown("**ì§ˆë¬¸:** ì œí’ˆì¹´í…Œê³ ë¦¬ ë¶„í¬ê°€ ì„±ë³„/ì—°ë ¹ì— í¸ì¤‘ë˜ì–´ ìˆì„ê¹Œ?")
        a, b = st.columns(2)

        with a:
            st.markdown("### 3-A. ì œí’ˆì¹´í…Œê³ ë¦¬ Ã— ì„±ë³„")
            ct = pd.crosstab(df["Product_Category"], df["Gender"])
            res = cramers_v_from_crosstab(ct)

            st.markdown(
                f"""
- Ï‡Â² = **{res['chi2']:.2f}**, dof={res['dof']}, p={res['p']:.3e}  
- Cramer's V = **{res['v']:.4f}** â†’ **{effect_badge(res['v'], 'v')}**
"""
            )

            # ratio chart (display labels)
            ct_disp = ct.copy()
            ct_disp.index = ct_disp.index.map(lambda x: val_to_ko("Product_Category", x))
            ct_disp.columns = ct_disp.columns.map(lambda x: val_to_ko("Gender", x))

            tmp_ratio = ct_disp.div(ct_disp.sum(axis=1), axis=0).reset_index()
            id_col = tmp_ratio.columns[0]  # 'Product_Category' or 'index' depending on index name
            ratio = tmp_ratio.melt(id_vars=id_col, var_name="ì„±ë³„", value_name="ë¹„ìœ¨")
            ratio = ratio.rename(columns={id_col: "ì œí’ˆì¹´í…Œê³ ë¦¬"})

            fig = px.bar(ratio, x="ì œí’ˆì¹´í…Œê³ ë¦¬", y="ë¹„ìœ¨", color="ì„±ë³„", barmode="group")
            fig.update_layout(yaxis_tickformat=".0%")
            st.plotly_chart(fig, use_container_width=True)

        with b:
            st.markdown("### 3-B. ì œí’ˆì¹´í…Œê³ ë¦¬ Ã— ì—°ë ¹ëŒ€")
            ct2 = pd.crosstab(df["Product_Category"], df["Age"])
            res2 = cramers_v_from_crosstab(ct2)

            st.markdown(
                f"""
- Ï‡Â² = **{res2['chi2']:.2f}**, dof={res2['dof']}, p={res2['p']:.3e}  
- Cramer's V = **{res2['v']:.4f}** â†’ **{effect_badge(res2['v'], 'v')}**
"""
            )

            ct2_disp = ct2.copy()
            ct2_disp.index = ct2_disp.index.map(lambda x: val_to_ko("Product_Category", x))
            ct2_disp.columns = ct2_disp.columns.map(lambda x: val_to_ko("Age", x))

            tmp_ratio2 = ct2_disp.div(ct2_disp.sum(axis=1), axis=0).reset_index()
            id_col2 = tmp_ratio2.columns[0]  # 'Product_Category' or 'index'
            ratio2 = tmp_ratio2.melt(id_vars=id_col2, var_name="ì—°ë ¹ëŒ€", value_name="ë¹„ìœ¨")
            ratio2 = ratio2.rename(columns={id_col2: "ì œí’ˆì¹´í…Œê³ ë¦¬"})

            fig2 = px.line(ratio2, x="ì—°ë ¹ëŒ€", y="ë¹„ìœ¨", color="ì œí’ˆì¹´í…Œê³ ë¦¬", markers=False)
            fig2.update_layout(yaxis_tickformat=".0%")
            st.plotly_chart(fig2, use_container_width=True)

# -----------------------------
# Tab 3: Cross heatmap
# -----------------------------
with tabs[2]:
    st.subheader("ë„ì‹œìœ í˜• Ã— ì œí’ˆì¹´í…Œê³ ë¦¬ í‰ê·  êµ¬ë§¤ê¸ˆì•¡ íˆíŠ¸ë§µ")
    st.caption("êµì°¨ ì„¸ê·¸ë¨¼íŠ¸ ëŠë‚Œì„ ê·¸ëŒ€ë¡œ ê°€ì ¸ì˜¤ë˜, í•„í„°ë¡œ ì¦‰ì‹œ ì¬ê³„ì‚°ë˜ëŠ” ë²„ì „ì…ë‹ˆë‹¤.")

    pivot = pd.pivot_table(
        df_disp,
        values="êµ¬ë§¤ê¸ˆì•¡",
        index="ë„ì‹œìœ í˜•",
        columns="ì œí’ˆì¹´í…Œê³ ë¦¬",
        aggfunc="mean",
        observed=True,
    )

    fig = px.imshow(pivot, aspect="auto", origin="lower")
    fig.update_layout(xaxis_title="ì œí’ˆì¹´í…Œê³ ë¦¬", yaxis_title="ë„ì‹œìœ í˜•")
    st.plotly_chart(fig, use_container_width=True)

    with st.expander("ì´ ì¡°í•©ì—ì„œ 'íŠ€ëŠ”' ì…€ ì°¾ê¸° (Top N)"):
        n_top = st.slider("Top N", 5, 30, 10)
        tmp = pivot.stack().reset_index()
        tmp.columns = ["ë„ì‹œìœ í˜•", "ì œí’ˆì¹´í…Œê³ ë¦¬", "í‰ê· êµ¬ë§¤ê¸ˆì•¡"]
        tmp = tmp.sort_values("í‰ê· êµ¬ë§¤ê¸ˆì•¡", ascending=False).head(n_top)
        tmp["í‰ê· êµ¬ë§¤ê¸ˆì•¡"] = tmp["í‰ê· êµ¬ë§¤ê¸ˆì•¡"].round(1)
        st.dataframe(tmp, use_container_width=True, hide_index=True)

# -----------------------------
# Tab 4: Segment top3
# -----------------------------
with tabs[3]:
    st.subheader("ì„¸ê·¸ë¨¼íŠ¸ TOP3 (mean/median + count ê°™ì´ ë³´ê¸°)")
    st.caption("ê·¸ë£¹ë³„ TOP3ë¥¼ ëŒ€ì‹œë³´ë“œìš©ìœ¼ë¡œ ì¬í˜„í–ˆì–´ìš”.")

    col1, col2 = st.columns([1, 1])
    with col1:
        target_col = st.selectbox(
            "ê·¸ë£¹ ë³€ìˆ˜ ì„ íƒ",
            ["Gender", "Age", "City_Category", "Stay_In_Current_City_Years", "Marital_Status", "Occupation", "Product_Category"],
            format_func=lambda x: CANON_TO_KO_COL.get(x, x),
        )
    with col2:
        sort_by = st.selectbox("ì •ë ¬ ê¸°ì¤€", ["mean", "median"])

    g = top3_groups(df, target_col)
    if len(g) == 0:
        st.info("í‘œë³¸ì´ ë¶€ì¡±í•´ì„œ ê³„ì‚°ì´ ì–´ë ¤ì›Œìš”. í•„í„°ë¥¼ ì¡°ê¸ˆ í’€ì–´ë³´ì„¸ìš”.")
    else:
        g2 = g.copy()
        g2[target_col] = g2[target_col].apply(lambda v: val_to_ko(target_col, v))

        g_sorted = g2.sort_values([sort_by, "count"], ascending=[False, False])
        st.dataframe(g_sorted.head(15), use_container_width=True, hide_index=True)

        top3 = g_sorted.head(3).copy()
        st.markdown("### TOP3 ìš”ì•½")
        for _, row in top3.iterrows():
            st.write(
                f"- {CANON_TO_KO_COL.get(target_col, target_col)} **{row[target_col]}** | "
                f"count={int(row['count']):,} | mean={row['mean']:,.1f} | median={row['median']:,.1f}"
            )

st.markdown(
    "<div class='small-note'>Tip: í•„í„°ë¥¼ ê³¼í•˜ê²Œ ê±¸ë©´ ê·¸ë£¹ì´ 1ê°œë§Œ ë‚¨ì•„ ê²€ì •ì´ ë¶ˆê°€ëŠ¥í•´ìš”. "
    "ê·¸ëŸ´ ë•ŒëŠ” (1) ë²”ì£¼í˜• í•„í„°ë¥¼ ì¤„ì´ê±°ë‚˜ (2) êµ¬ë§¤ê¸ˆì•¡ ë²”ìœ„ë¥¼ ë„“í˜€ë³´ì„¸ìš”.</div>",
    unsafe_allow_html=True,
)
